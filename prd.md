## **PRD: 实时对话 AI 助手 (POC 阶段)**

| **文档版本** | **V1.0**                                                                                                                                   | **创建日期**   | 2023-10-27 |
| :----------- | :----------------------------------------------------------------------------------------------------------------------------------------- | :------------- | :--------- |
| **项目名称** | 实时对话 AI 助手 (Project "EchoFlow")                                                                                                      | **产品负责人** | [您的名字] |
| **目标**     | 构建一个基于火山引擎服务的高性能、低成本、可打断的对话式 AI 原型，以验证其核心能力和用户体验，作为对标 ElevenLabs 等集成方案的可行性研究。 |

### 1. 项目背景与目标

#### 1.1 背景

当前市面上的高级对话式 AI 服务（如 ElevenLabs Conversation AI）虽然功能强大，但其封装的模式导致成本高昂且灵活性不足。以 ElevenLabs 为例，$22/月的套餐仅支持约 100 分钟的对话时长。通过自建管道，利用火山引擎（豆包 TTS、豆包大模型、语音识别）的独立服务，预计能以同等价格支持超过 10000 分钟的调用，并获得完全的定制化能力。

本项目旨在利用 Next.js 前端框架、FastAPI 后端以及 n8n 作为外部工具调用器，构建一个功能对齐、成本显著降低的对话 AI 原型。

#### 1.2 核心目标

1.  **功能验证 (Feasibility):** 证明通过组合火山引擎的原子服务，可以实现包含工具调用、实时流式交互和语音打断在内的完整对话体验。
2.  **性能基准 (Performance):** 达成低延迟的用户体验。**目标：从用户说话结束到 AI 开始响应的“思考延迟”低于 1.5 秒**。
3.  **成本效益 (Cost-Effectiveness):** 验证该架构在成本控制上的巨大优势，尤其是在语音合成（TTS）的可打断设计上。
4.  **技术蓝图 (Blueprint):** 为未来产品的迭代开发提供一个经过验证的技术架构和实施方案。

---

### 2. 用户画像与核心场景

#### 2.1 用户画像

- **角色:** POC 阶段开发者/产品经理 (Alex)
- **需求:** 需要快速验证一个想法，即能否用更经济、更灵活的方式构建一个智能语音助手。
- **痛点:** 对现有方案的成本和“黑盒”模式感到不满，希望对系统的每个环节都有控制力。

#### 2.2 核心用户场景

1.  **场景一：流畅的问答与工具调用**

    - Alex 打开应用，点击“开始通话”。
    - 系统状态变为“正在聆听...”。
    - Alex 说：“帮我查一下上海今天的天气怎么样，然后推荐一个附近的咖啡馆。”
    - Alex 说完话后，系统自动检测到静音，状态变为“正在思考...”。
    - 后端 LLM 识别出两个任务，调用 n8n webhook 执行天气查询和地点推荐。
    - 系统状态变为“正在说话...”，并开始流式播报：“上海今天多云，26 摄氏度。为您推荐附近的星巴克咖啡...”。

2.  **场景二：自然的对话打断**
    - AI 正在播报：“...星巴克咖啡，它位于人民广场...”
    - Alex 不等它说完，直接打断并说：“不，我更喜欢独立咖啡馆。”
    - AI 的播报立刻停止，系统状态变回“正在聆听...”。
    - Alex 说完后，系统状态变为“正在思考...”。
    - 后端 LLM 接收到新的指令，重新调用 n8n（或基于新指令生成回答）。
    - 系统开始播报新的结果：“好的，为您找到一家高分独立咖啡馆，名叫‘Seesaw Coffee’...”。

---

### 3. 功能需求 (Functional Requirements)

| ID        | 功能模块                        | 需求描述                                                                                                                                                                                                     | 优先级 |
| :-------- | :------------------------------ | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----- |
| **FR-01** | **通话式交互界面**              | 提供一个简洁的前端界面。包含一个“开始/结束通话”按钮、一个清晰的状态指示器（如：准备就绪、聆听中、思考中、说话中）和一个用于展示识别文本（可选）的区域。                                                      | **高** |
| **FR-02** | **实时语音流传输**              | 用户点击“开始通话”后，前端通过`MediaRecorder`捕获麦克风音频，以小数据块（如 200ms）的形式，通过 WebSocket 实时传输到后端。                                                                                   | **高** |
| **FR-03** | **前端语音活动检测 (VAD)**      | 1. **自动结束检测**: 在用户说话时，前端 VAD 能检测到语音结束后的静音，自动触发“一句话结束”的逻辑，无需用户手动点击。 2. **打断检测**: 在 AI 说话时，VAD 保持监听，一旦检测到用户开始说话，立即触发打断逻辑。 | **高** |
| **FR-04** | **流式语音转文本 (STT)**        | 后端接收音频流，实时调用火山引擎流式 STT 服务。可将临时的“中间识别结果”发回前端展示，提高交互的即时感。在收到“最终识别结果”后，触发 LLM。                                                                    | **高** |
| **FR-05** | **LLM 意图理解与 n8n 工具调用** | 后端将 STT 的最终文本和预定义的`n8n`工具描述一起发送给豆包大模型。若模型判断需要调用工具，后端则向 n8n 的 Webhook URL 发送请求，并将返回结果再次提交给模型以生成最终回答。                                   | **高** |
| **FR-06** | **流式语音合成 (TTS)**          | 后端获取 LLM 生成的最终文本后，调用火山引擎豆包 TTS 的流式接口，将生成的音频流通过 WebSocket 实时传回前端播放，实现边生成边播放的低延迟效果。                                                                | **高** |
| **FR-07** | **语音打断 (Barge-in)**         | 1. **前端**: 检测到打断时，立即停止播放 AI 音频，并向后端发送“打断”信号。 2. **后端**: 收到“打断”信号后，必须立即取消正在进行的 TTS 任务，并准备处理用户的新一轮输入。                                       | **高** |

---

### 4. 技术架构与选型

#### 4.1 整体架构图

```
+--------------------------------+       WebSocket       +-----------------------------+
|        前端 (Next.js)          |---------------------->|       后端 (FastAPI)        |
|                                |      (Audio Stream,    |<----------------------|      (Audio Stream,      |
| +--------------------------+   |       Events)          |   +-------------------+   |       Events)          |
| |       UI Components      |   |                        |   | WebSocket Handler |   |                        |
| |   (Button, Status)       |   |                        |   +-------------------+   |                        |
| +--------------------------+   |                        |             |             |                        |
| | MediaRecorder (Recording)|   |                        |             v             |                        |
| +--------------------------+   |                        |   +-------------------+   |                        |
| | VAD (@ricky0123/vad-web) |   |                        |   | Conversation Orchestrator |   |                        |
| +--------------------------+   |                        |   +-------------------+   |                        |
| | AudioPlayer (Streaming)  |   |                        |   | |STT|->|LLM|->|TTS| |   |                        |
| +--------------------------+   |                        |   +-+---+--+---+--+---+---+                        |
+--------------------------------+                       |             |             |                        |
                                                         +-------------|---------------+
                                                                       | (API Calls)
                                                                       v
       +------------------------------------+--------------------------+----------------------------------+
       |       火山引擎 (Volcengine)          |                          |        外部工具 (n8n)            |
       | +--------------------------------+ |                          | +------------------------------+ |
       | | 流式语音识别 (Streaming STT)   | | <------------------------+ |          Webhook URL           | |
       | +--------------------------------+ |                          | +------------------------------+ |
       | | 豆包大模型 (Doubao LLM)        | |                          +----------------------------------+
       | |    - Function Calling          | |
       | +--------------------------------+ |
       | | 流式语音合成 (Streaming TTS)   | |
       | +--------------------------------+ |
       +------------------------------------+
```

#### 4.2 技术选型

| 层次             | 技术/服务                                      | 备注                                                      |
| :--------------- | :--------------------------------------------- | :-------------------------------------------------------- |
| **前端**         | Next.js, React 18, TypeScript                  | 现代 Web 应用框架，支持 SSR 和组件化。                    |
| **前端音频处理** | `MediaRecorder` API, `@ricky0123/vad-web`      | 用于音频捕获和语音活动检测。                              |
| **实时通信**     | WebSocket                                      | 用于前后端低延迟、双向数据流。                            |
| **后端**         | Python 3.10+, FastAPI                          | 高性能异步 Web 框架，完美支持 WebSocket。                 |
| **后端核心库**   | `volcengine-python-sdk`, `websockets`, `httpx` | 分别用于调用火山云服务、处理 WebSocket 和发送 HTTP 请求。 |
| **语音识别**     | 火山引擎 流式语音识别                          | 实时将用户语音流转换为文本。                              |
| **语言模型**     | 火山引擎 豆包大模型 (Pro/Skylark)              | 负责意图理解和函数调用（工具调用）。                      |
| **语音合成**     | 火山引擎 豆包 TTS (流式)                       | 将文本实时合成为语音流。                                  |
| **工具执行**     | n8n (Webhook)                                  | 作为外部工具的执行器，与主应用解耦。                      |

---

### 5. 非功能性需求

| 类别         | 需求描述                                                                                                                            |
| :----------- | :---------------------------------------------------------------------------------------------------------------------------------- |
| **性能**     | **端到端延迟**: 从用户说完话到 AI 开始说话的延迟应 < 1.5 秒。**首字延迟**: AI 开始说话后，第一个音频包到达前端的时间应 < 300 毫秒。 |
| **可用性**   | 界面状态反馈必须清晰、及时，避免用户困惑。交互逻辑应符合打电话的自然习惯。                                                          |
| **健壮性**   | 系统能优雅地处理网络中断和 API 调用失败（如：向用户提示“网络错误，请重试”）。                                                       |
| **成本控制** | 后端逻辑必须在收到打断信号时，能有效终止对 TTS API 的后续请求，以节省不必要的开销。                                                 |

---

### 6. 实施计划 (里程碑)

1.  **里程碑 1 (V0.1 - 核心管道搭建):**

    - 【后端】搭建 FastAPI 服务，实现对火山云 STT、LLM（无工具）、TTS 的 API 调用。
    - 【前端】搭建 Next.js 基础页面，实现手动录音上传、接收并播放完整的音频文件。
    - **目标:** 验证三项核心服务的连通性。

2.  **里程碑 2 (V0.5 - 实现流式与 VAD):**

    - 【前后端】改造为 WebSocket 流式通信。
    - 【后端】集成流式 STT 和流式 TTS。
    - 【前端】集成 VAD 库，实现自动检测语音结束，替换手动停止按钮。
    - **目标:** 实现流畅、自然的“通话式”交互。

3.  **里程碑 3 (V1.0 - 实现工具调用与打断):**
    - 【后端】在 LLM 调用中加入 n8n 的函数调用逻辑。
    - 【前后端】实现完整的打断（Barge-in）逻辑。
    - **目标:** 完成 PRD 中定义的所有核心功能，达到可演示状态。

---

### 7. 风险与预案

| 风险点             | 可能性 | 影响 | 应对预案                                                                                         |
| :----------------- | :----- | :--- | :----------------------------------------------------------------------------------------------- |
| **网络延迟不可控** | 中     | 高   | 确保前后端、火山云服务部署在同一地理区域。优化音频编解码格式以减小数据量。                       |
| **VAD 准确率不高** | 中     | 中   | VAD 库提供多种参数（如静音阈值、延迟时间）可供调整，需要针对实际场景进行调优。                   |
| **API 调用失败**   | 低     | 高   | 在后端对所有外部 API 调用增加重试机制和错误捕获，并通过 WebSocket 向前端反馈明确的错误状态。     |
| **上下文管理**     | 中     | 中   | POC 阶段，每次通话保持独立上下文。未来版本需设计上下文窗口或摘要机制，以控制 LLM 的 Token 成本。 |
