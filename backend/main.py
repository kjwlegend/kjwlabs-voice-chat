"""
FastAPIä¸»åº”ç”¨ç¨‹åº
å®æ—¶å¯¹è¯AIåŠ©æ‰‹åç«¯æœåŠ¡
"""

import asyncio
import base64
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import json
import logging
from typing import Dict, Any, Optional, List
from io import BytesIO
import subprocess
import tempfile
import os

# å¯¼å…¥æœåŠ¡æ¨¡å—
from services import VolcengineService
from config import config

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, config.LOG_LEVEL),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="EchoFlow AI Assistant", description="å®æ—¶å¯¹è¯AIåŠ©æ‰‹åç«¯æœåŠ¡", version="1.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.get_cors_origins(),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€æœåŠ¡å®ä¾‹
volcengine_service: Optional[VolcengineService] = None


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    global volcengine_service

    logger.info("=== ğŸš€ EchoFlow AI Assistant Starting ===")
    config.print_config()

    # åˆå§‹åŒ–ç«å±±å¼•æ“æœåŠ¡
    if config.has_voice_config():
        try:
            volcengine_service = VolcengineService(
                access_key=config.VOLCENGINE_ACCESS_KEY,
                secret_key=config.VOLCENGINE_SECRET_KEY,
                app_id=config.VOLCENGINE_APP_ID,
                api_key=(
                    config.VOLCENGINE_API_KEY if config.VOLCENGINE_API_KEY else None
                ),
                endpoint_id=(
                    config.VOLCENGINE_ENDPOINT_ID
                    if config.VOLCENGINE_ENDPOINT_ID
                    else None
                ),
                n8n_webhook_url=config.N8N_WEBHOOK_URL,
            )

            logger.info("[Startup] ğŸ”Š ç«å±±å¼•æ“è¯­éŸ³æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")

            if config.has_llm_config():
                logger.info("[Startup] ğŸ¤– ç«å±±å¼•æ“LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("[Startup] âš ï¸  LLMæœåŠ¡æœªé…ç½®ï¼Œå¤§æ¨¡å‹å¯¹è¯åŠŸèƒ½å°†ä¸å¯ç”¨")

            # æµ‹è¯•æœåŠ¡è¿æ¥
            try:
                test_results = await volcengine_service.test_services()
                logger.info(f"[Startup] ğŸ§ª æœåŠ¡æµ‹è¯•ç»“æœ: {test_results}")
            except Exception as test_error:
                logger.warning(f"[Startup] âš ï¸  æœåŠ¡æµ‹è¯•å¤±è´¥: {test_error}")

        except Exception as e:
            logger.error(f"[Startup] âŒ ç«å±±å¼•æ“æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            if not config.ENABLE_MOCK_SERVICES:
                raise HTTPException(status_code=500, detail="æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
    else:
        logger.warning("[Startup] âš ï¸  ç«å±±å¼•æ“é…ç½®ä¸å®Œæ•´ï¼ŒæŸäº›åŠŸèƒ½å°†ä¸å¯ç”¨")
        logger.info(
            "[Startup] è¯·é…ç½®ç¯å¢ƒå˜é‡: VOLCENGINE_ACCESS_KEY, VOLCENGINE_SECRET_KEY, VOLCENGINE_APP_ID"
        )


# å­˜å‚¨WebSocketè¿æ¥å’Œå¯¹è¯çŠ¶æ€
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.conversation_states: Dict[str, Dict[str, Any]] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        """å»ºç«‹WebSocketè¿æ¥"""
        await websocket.accept()
        self.active_connections[client_id] = websocket

        # åˆå§‹åŒ–å¯¹è¯çŠ¶æ€
        self.conversation_states[client_id] = {
            "messages": [],  # å¯¹è¯å†å²
            "current_audio_chunks": [],  # å½“å‰éŸ³é¢‘å—
            "is_processing": False,  # æ˜¯å¦æ­£åœ¨å¤„ç†
            "last_activity": asyncio.get_event_loop().time(),
        }

        logger.info(f"[ConnectionManager] å®¢æˆ·ç«¯ {client_id} å·²è¿æ¥")

        # å‘é€è¿æ¥ç¡®è®¤
        await self.send_message(
            client_id,
            {
                "type": "connection_established",
                "data": {"client_id": client_id, "status": "connected"},
            },
        )

    def disconnect(self, client_id: str):
        """æ–­å¼€è¿æ¥"""
        if client_id in self.active_connections:
            del self.active_connections[client_id]
        if client_id in self.conversation_states:
            del self.conversation_states[client_id]
        logger.info(f"[ConnectionManager] å®¢æˆ·ç«¯ {client_id} å·²æ–­å¼€è¿æ¥")

    async def send_message(self, client_id: str, message: dict):
        """å‘é€æ¶ˆæ¯ç»™å®¢æˆ·ç«¯"""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_text(json.dumps(message))
                logger.debug(
                    f"[ConnectionManager] å‘é€æ¶ˆæ¯ç»™ {client_id}: {message['type']}"
                )
            except Exception as e:
                logger.error(f"[ConnectionManager] å‘é€æ¶ˆæ¯å¤±è´¥ {client_id}: {e}")
                self.disconnect(client_id)

    def get_conversation_state(self, client_id: str) -> Dict[str, Any]:
        """è·å–å¯¹è¯çŠ¶æ€"""
        return self.conversation_states.get(client_id, {})

    def update_conversation_state(self, client_id: str, updates: Dict[str, Any]):
        """æ›´æ–°å¯¹è¯çŠ¶æ€"""
        if client_id in self.conversation_states:
            self.conversation_states[client_id].update(updates)


# è¿æ¥ç®¡ç†å™¨å®ä¾‹
manager = ConnectionManager()


@app.get("/")
async def root():
    """æ ¹è·¯å¾„å¥åº·æ£€æŸ¥"""
    return {
        "message": "EchoFlow AI Assistant Backend is running",
        "version": "1.0.0",
        "status": "healthy",
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    service_status = "available" if volcengine_service else "unavailable"
    llm_status = (
        "available" if volcengine_service and config.has_llm_config() else "unavailable"
    )
    voice_status = (
        "available"
        if volcengine_service and config.has_voice_config()
        else "unavailable"
    )

    return {
        "status": "healthy",
        "service": "EchoFlow AI Assistant",
        "volcengine_service": service_status,
        "llm_service": llm_status,
        "voice_service": voice_status,
        "timestamp": asyncio.get_event_loop().time(),
    }


@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """WebSocketè¿æ¥å¤„ç†"""
    await manager.connect(websocket, client_id)
    try:
        while True:
            # æ¥æ”¶å®¢æˆ·ç«¯æ¶ˆæ¯
            data = await websocket.receive_text()
            message = json.loads(data)

            logger.debug(
                f"[WebSocket] æ”¶åˆ°å®¢æˆ·ç«¯ {client_id} æ¶ˆæ¯: {message.get('type')}"
            )

            # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
            await handle_message(client_id, message)

    except WebSocketDisconnect:
        manager.disconnect(client_id)
        logger.info(f"[WebSocket] å®¢æˆ·ç«¯ {client_id} æ–­å¼€è¿æ¥")
    except Exception as e:
        logger.error(f"[WebSocket] å¤„ç†æ¶ˆæ¯é”™è¯¯: {e}")
        manager.disconnect(client_id)


async def handle_message(client_id: str, message: dict):
    """å¤„ç†WebSocketæ¶ˆæ¯"""
    message_type = message.get("type")
    message_data = message.get("data", {})

    try:
        if message_type == "audio_chunk":
            # å¤„ç†éŸ³é¢‘æµæ•°æ®
            await process_audio_chunk(client_id, message_data)
        elif message_type == "interrupt":
            # å¤„ç†è¯­éŸ³æ‰“æ–­
            await process_interrupt(client_id)
        elif message_type == "start_conversation":
            # å¼€å§‹å¯¹è¯
            await start_conversation(client_id)
        elif message_type == "end_conversation":
            # ç»“æŸå¯¹è¯
            await end_conversation(client_id)
        elif message_type == "heartbeat":
            # å¿ƒè·³æ£€æµ‹
            await manager.send_message(
                client_id,
                {
                    "type": "heartbeat_ack",
                    "data": {"timestamp": asyncio.get_event_loop().time()},
                },
            )
        else:
            logger.warning(f"[WebSocket] æœªçŸ¥æ¶ˆæ¯ç±»å‹: {message_type}")

    except Exception as e:
        logger.error(f"[WebSocket] å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
        await manager.send_message(
            client_id,
            {
                "type": "error",
                "data": {
                    "code": "PROCESSING_ERROR",
                    "message": f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}",
                    "retryable": True,
                },
            },
        )


async def process_audio_chunk(client_id: str, audio_data: dict):
    """å¤„ç†éŸ³é¢‘æµæ•°æ®"""
    try:
        logger.debug(f"[AudioProcessor] å¤„ç†å®¢æˆ·ç«¯ {client_id} çš„éŸ³é¢‘æ•°æ®")

        # è·å–å¯¹è¯çŠ¶æ€
        conv_state = manager.get_conversation_state(client_id)

        if conv_state.get("is_processing"):
            logger.debug(f"[AudioProcessor] å®¢æˆ·ç«¯ {client_id} æ­£åœ¨å¤„ç†ä¸­ï¼Œå¿½ç•¥éŸ³é¢‘å—")
            return

        # è·å–éŸ³é¢‘æ•°æ®
        audio_base64 = audio_data.get("audioData")
        is_last = audio_data.get("isLast", False)

        if not audio_base64:
            logger.warning(f"[AudioProcessor] å®¢æˆ·ç«¯ {client_id} å‘é€çš„éŸ³é¢‘æ•°æ®ä¸ºç©º")
            # å¦‚æœæ˜¯æœ€åä¸€å—ä¸”ä¸ºç©ºï¼Œè¯´æ˜å½•åˆ¶ç»“æŸï¼Œå¼€å§‹å¤„ç†ç´¯ç§¯çš„éŸ³é¢‘
            if is_last:
                await process_accumulated_audio(client_id)
            return

        # è§£ç éŸ³é¢‘æ•°æ®
        try:
            audio_bytes = base64.b64decode(audio_base64)
            if len(audio_bytes) > 0:
                # ç´¯ç§¯éŸ³é¢‘æ•°æ®
                accumulated_audio = conv_state.get("accumulated_audio", b"")
                accumulated_audio += audio_bytes
                manager.update_conversation_state(
                    client_id, {"accumulated_audio": accumulated_audio}
                )
                logger.debug(
                    f"[AudioProcessor] ç´¯ç§¯éŸ³é¢‘æ•°æ®ï¼Œæ€»å¤§å°: {len(accumulated_audio)} bytes"
                )
        except Exception as decode_error:
            logger.error(f"[AudioProcessor] Base64è§£ç å¤±è´¥: {str(decode_error)}")
            return

        if is_last:
            # æœ€åä¸€ä¸ªéŸ³é¢‘å—ï¼Œå¼€å§‹å¤„ç†ç´¯ç§¯çš„éŸ³é¢‘
            await process_accumulated_audio(client_id)

    except Exception as e:
        logger.error(f"[AudioProcessor] å¤„ç†éŸ³é¢‘å¤±è´¥: {e}")
        manager.update_conversation_state(client_id, {"is_processing": False})
        await manager.send_message(
            client_id,
            {
                "type": "error",
                "data": {
                    "code": "AUDIO_PROCESSING_ERROR",
                    "message": f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}",
                    "retryable": True,
                },
            },
        )


async def process_accumulated_audio(client_id: str):
    """å¤„ç†ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®"""
    try:
        logger.info(f"[AudioProcessor] å¼€å§‹å¤„ç†å®¢æˆ·ç«¯ {client_id} çš„å®Œæ•´éŸ³é¢‘")

        # è·å–ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®
        conv_state = manager.get_conversation_state(client_id)
        accumulated_audio = conv_state.get("accumulated_audio", b"")

        if not accumulated_audio or len(accumulated_audio) == 0:
            logger.warning(f"[AudioProcessor] å®¢æˆ·ç«¯ {client_id} æ²¡æœ‰ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®")
            return

        # ä¿å­˜éŸ³é¢‘æ•°æ®ç”¨äºè°ƒè¯•
        debug_audio_path = (
            f"debug_audio_{client_id}_{int(asyncio.get_event_loop().time())}.webm"
        )
        try:
            with open(debug_audio_path, "wb") as f:
                f.write(accumulated_audio)
            logger.info(f"[AudioProcessor] éŸ³é¢‘æ•°æ®å·²ä¿å­˜åˆ°: {debug_audio_path}")
        except Exception as save_error:
            logger.error(f"[AudioProcessor] ä¿å­˜éŸ³é¢‘æ•°æ®å¤±è´¥: {save_error}")

        # æ ‡è®°ä¸ºå¤„ç†ä¸­
        manager.update_conversation_state(
            client_id,
            {"is_processing": True, "accumulated_audio": b""},  # æ¸…ç©ºç´¯ç§¯çš„éŸ³é¢‘
        )

        try:
            logger.info(
                f"[AudioProcessor] å¤„ç†éŸ³é¢‘æ•°æ®ï¼Œå¤§å°: {len(accumulated_audio)} bytes"
            )

            # æ£€æŸ¥éŸ³é¢‘æ ¼å¼
            logger.info(f"[AudioProcessor] éŸ³é¢‘æ•°æ®å‰16å­—èŠ‚: {accumulated_audio[:16]}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºWAVæ ¼å¼
            if accumulated_audio[:4] == b"RIFF" and accumulated_audio[8:12] == b"WAVE":
                logger.info("[AudioProcessor] æ£€æµ‹åˆ°WAVæ ¼å¼éŸ³é¢‘")
            else:
                logger.warning("[AudioProcessor] éŸ³é¢‘æ ¼å¼ä¸æ˜¯WAVï¼Œå¯èƒ½å½±å“STTè¯†åˆ«æ•ˆæœ")

            # è°ƒç”¨STTæœåŠ¡
            await manager.send_message(
                client_id,
                {"type": "stt_start", "data": {"message": "å¼€å§‹è¯­éŸ³è¯†åˆ«..."}},
            )

            if volcengine_service:
                # ç›´æ¥è°ƒç”¨æ–°çš„è¯­éŸ³è¯†åˆ«æ–¹æ³•ï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†æ ¼å¼è½¬æ¢
                stt_text = await volcengine_service.speech_to_text(accumulated_audio)

                # æ„å»ºç»“æœæ ¼å¼
                stt_result = {
                    "type": "final",
                    "text": stt_text,
                    "confidence": 0.95,
                    "is_final": True,
                }
            else:
                # é™çº§å¤„ç† - æ¨¡æ‹ŸSTTç»“æœ
                stt_result = {
                    "type": "final",
                    "text": "ä½ å¥½ï¼Œè¿™æ˜¯è¯­éŸ³è¯†åˆ«çš„æµ‹è¯•ç»“æœã€‚å½“å‰éŸ³é¢‘å¤§å°: "
                    + str(len(accumulated_audio))
                    + " bytes",
                    "confidence": 0.8,
                    "is_final": True,
                }

            recognized_text = stt_result.get("text", "")
            logger.info(f"[AudioProcessor] STTç»“æœ: {recognized_text}")

            if not recognized_text or "æ¨¡æ‹Ÿç»“æœ" in recognized_text:
                await manager.send_message(
                    client_id,
                    {"type": "stt_result", "data": stt_result},
                )
                # å¦‚æœæ˜¯æ¨¡æ‹Ÿç»“æœï¼Œä»ç„¶ç»§ç»­å¤„ç†ï¼Œç”¨äºæµ‹è¯•
                if "æ¨¡æ‹Ÿç»“æœ" not in recognized_text:
                    return

            # å‘é€STTç»“æœ
            await manager.send_message(
                client_id, {"type": "stt_result", "data": stt_result}
            )

            # è°ƒç”¨LLMç”Ÿæˆå›å¤
            await process_llm_conversation(client_id, recognized_text)

        finally:
            # å¤„ç†å®Œæˆï¼Œé‡ç½®çŠ¶æ€
            manager.update_conversation_state(client_id, {"is_processing": False})

    except Exception as e:
        logger.error(f"[AudioProcessor] å¤„ç†ç´¯ç§¯éŸ³é¢‘å¤±è´¥: {e}")
        manager.update_conversation_state(client_id, {"is_processing": False})
        await manager.send_message(
            client_id,
            {
                "type": "error",
                "data": {
                    "code": "AUDIO_PROCESSING_ERROR",
                    "message": f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}",
                    "retryable": True,
                },
            },
        )


async def convert_audio_to_wav(audio_data: bytes, input_path: str) -> Optional[bytes]:
    """
    å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºWAVæ ¼å¼ - ç»Ÿä¸€ä½¿ç”¨STTAudioUtils

    Args:
        audio_data: åŸå§‹éŸ³é¢‘æ•°æ®
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºæ£€æµ‹æ ¼å¼ï¼‰

    Returns:
        Optional[bytes]: è½¬æ¢åçš„WAVæ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        from services.volcengine_stt import STTAudioUtils

        logger.info("[AudioConverter] å¼€å§‹éŸ³é¢‘æ ¼å¼è½¬æ¢")

        # æ£€æµ‹éŸ³é¢‘æ ¼å¼
        audio_format = STTAudioUtils.detect_audio_format(audio_data)
        logger.info(f"[AudioConverter] æ£€æµ‹åˆ°éŸ³é¢‘æ ¼å¼: {audio_format}")

        # å¦‚æœå·²ç»æ˜¯WAVæ ¼å¼ï¼Œç›´æ¥è¿”å›
        if audio_format == "wav":
            logger.info("[AudioConverter] éŸ³é¢‘å·²æ˜¯WAVæ ¼å¼ï¼Œæ— éœ€è½¬æ¢")
            return audio_data

        # ä½¿ç”¨STTAudioUtilsè½¬æ¢
        wav_data = STTAudioUtils.convert_to_wav(audio_data, audio_format)

        logger.info(f"[AudioConverter] è½¬æ¢æˆåŠŸï¼ŒWAVæ•°æ®å¤§å°: {len(wav_data)} bytes")

        # ä¿å­˜è½¬æ¢åçš„WAVæ–‡ä»¶ç”¨äºè°ƒè¯•
        debug_wav_path = input_path.replace(".webm", "_converted.wav")
        with open(debug_wav_path, "wb") as f:
            f.write(wav_data)
        logger.info(f"[AudioConverter] è½¬æ¢åçš„WAVæ–‡ä»¶å·²ä¿å­˜åˆ°: {debug_wav_path}")

        return wav_data

    except Exception as e:
        logger.error(f"[AudioConverter] éŸ³é¢‘è½¬æ¢å¼‚å¸¸: {e}")
        return None


async def process_llm_conversation(client_id: str, user_text: str):
    """å¤„ç†LLMå¯¹è¯ï¼ˆæ”¯æŒåŒè·¯å¾„å“åº”ï¼‰"""
    try:
        logger.info(f"[LLMProcessor] å¤„ç†å®¢æˆ·ç«¯ {client_id} çš„å¯¹è¯: {user_text}")

        # è·å–å¯¹è¯å†å²
        conv_state = manager.get_conversation_state(client_id)
        messages = conv_state.get("messages", [])

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_text})

        # å‘é€LLMå¤„ç†å¼€å§‹ä¿¡å·
        await manager.send_message(
            client_id, {"type": "llm_start", "data": {"message": "AIæ­£åœ¨æ€è€ƒ..."}}
        )

        # è°ƒç”¨LLMæœåŠ¡
        if volcengine_service and config.has_llm_config():
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å¢å¼ºç‰ˆLLMæœåŠ¡
            if volcengine_service.is_enhanced_llm_enabled():
                logger.info(f"[LLMProcessor] ä½¿ç”¨åŒè·¯å¾„LLMå“åº”")
                # ä½¿ç”¨åŒè·¯å¾„å“åº”
                await process_dual_path_llm_response(client_id, messages)
            else:
                logger.info(f"[LLMProcessor] ä½¿ç”¨ä¼ ç»ŸLLMå“åº”")
                # ä½¿ç”¨ä¼ ç»Ÿå•ä¸€å“åº”
                await process_traditional_llm_response(client_id, messages)
        else:
            # é™çº§å¤„ç†
            ai_response = "ä½ å¥½ï¼æˆ‘æ˜¯EchoFlow AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å½“å‰LLMæœåŠ¡æœªé…ç½®ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå›å¤ã€‚"
            await process_fallback_llm_response(client_id, messages, ai_response)

    except Exception as e:
        logger.error(f"[LLMProcessor] å¤„ç†LLMå¯¹è¯å¤±è´¥: {e}")
        manager.update_conversation_state(client_id, {"is_processing": False})
        await manager.send_message(
            client_id,
            {
                "type": "error",
                "data": {
                    "code": "LLM_PROCESSING_ERROR",
                    "message": f"LLMå¤„ç†å¤±è´¥: {str(e)}",
                    "retryable": True,
                },
            },
        )


async def process_dual_path_llm_response(
    client_id: str, messages: List[Dict[str, Any]]
):
    """å¤„ç†åŒè·¯å¾„LLMå“åº”"""
    try:
        logger.info(f"[LLMProcessor] å¼€å§‹åŒè·¯å¾„LLMå¤„ç†")

        # å®šä¹‰å³æ—¶å“åº”å›è°ƒï¼ˆç”¨äºç«‹å³TTSï¼‰
        async def immediate_callback(immediate_text: str):
            logger.info(f"[LLMProcessor] æ”¶åˆ°å³æ—¶å“åº”: {immediate_text[:100]}...")

            # å‘é€ç«‹å³å“åº”
            await manager.send_message(
                client_id,
                {
                    "type": "llm_immediate_response",
                    "data": {
                        "text": immediate_text,
                        "is_immediate": True,
                        "timestamp": asyncio.get_event_loop().time(),
                    },
                },
            )

            # ç«‹å³ç”ŸæˆTTSéŸ³é¢‘
            await process_tts_generation(client_id, immediate_text, is_immediate=True)

        # å®šä¹‰è€å¿ƒç­‰å¾…å›è°ƒ
        async def patience_callback(patience_message: str):
            logger.info(f"[LLMProcessor] è€å¿ƒç­‰å¾…æ¶ˆæ¯: {patience_message}")

            # å‘é€è€å¿ƒç­‰å¾…æ¶ˆæ¯
            await manager.send_message(
                client_id,
                {
                    "type": "llm_patience_update",
                    "data": {
                        "message": patience_message,
                        "timestamp": asyncio.get_event_loop().time(),
                    },
                },
            )

        # è°ƒç”¨åŒè·¯å¾„LLMæœåŠ¡
        dual_response = await volcengine_service.generate_dual_path_response(
            messages,
            immediate_callback=immediate_callback,
            patience_callback=patience_callback,
        )

        # æ›´æ–°å¯¹è¯å†å²ï¼ˆä½¿ç”¨æœ€ç»ˆå“åº”ï¼‰
        final_content = (
            dual_response.tool_response
            if dual_response.has_tool_calls
            else dual_response.immediate_response
        )
        messages.append({"role": "assistant", "content": final_content})
        manager.update_conversation_state(client_id, {"messages": messages})

        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå‘é€æœ€ç»ˆå“åº”
        if dual_response.has_tool_calls:
            logger.info(
                f"[LLMProcessor] å‘é€æœ€ç»ˆèåˆå“åº”: {dual_response.tool_response[:100]}..."
            )

            await manager.send_message(
                client_id,
                {
                    "type": "llm_final_response",
                    "data": {
                        "text": dual_response.tool_response,
                        "is_final": True,
                        "has_tool_calls": True,
                        "tool_execution_time": dual_response.tool_execution_time,
                        "timestamp": asyncio.get_event_loop().time(),
                    },
                },
            )

            # ç”Ÿæˆæœ€ç»ˆå“åº”çš„TTSéŸ³é¢‘
            await process_tts_generation(
                client_id, dual_response.tool_response, is_final=True
            )
        else:
            logger.info(f"[LLMProcessor] æ— å·¥å…·è°ƒç”¨ï¼ŒåŒè·¯å¾„å¤„ç†å®Œæˆ")

    except Exception as e:
        logger.error(f"[LLMProcessor] åŒè·¯å¾„LLMå¤„ç†å¤±è´¥: {e}")
        raise


async def process_traditional_llm_response(
    client_id: str, messages: List[Dict[str, Any]]
):
    """å¤„ç†ä¼ ç»Ÿå•ä¸€LLMå“åº”"""
    try:
        ai_response = await volcengine_service.generate_chat_response(messages)

        if not ai_response:
            ai_response = "æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç†è§£æ‚¨çš„é—®é¢˜ï¼Œè¯·å†è¯´ä¸€éã€‚"

        logger.info(f"[LLMProcessor] ä¼ ç»ŸLLMå›å¤: {ai_response[:100]}...")

        # æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
        messages.append({"role": "assistant", "content": ai_response})
        manager.update_conversation_state(client_id, {"messages": messages})

        # å‘é€LLMç»“æœ
        await manager.send_message(
            client_id,
            {
                "type": "llm_response",
                "data": {
                    "text": ai_response,
                    "timestamp": asyncio.get_event_loop().time(),
                },
            },
        )

        # è°ƒç”¨TTSç”Ÿæˆè¯­éŸ³
        await process_tts_generation(client_id, ai_response)

    except Exception as e:
        logger.error(f"[LLMProcessor] ä¼ ç»ŸLLMå¤„ç†å¤±è´¥: {e}")
        raise


async def process_fallback_llm_response(
    client_id: str, messages: List[Dict[str, Any]], ai_response: str
):
    """å¤„ç†é™çº§LLMå“åº”"""
    try:
        logger.info(f"[LLMProcessor] é™çº§LLMå›å¤: {ai_response[:100]}...")

        # æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
        messages.append({"role": "assistant", "content": ai_response})
        manager.update_conversation_state(client_id, {"messages": messages})

        # å‘é€LLMç»“æœ
        await manager.send_message(
            client_id,
            {
                "type": "llm_response",
                "data": {
                    "text": ai_response,
                    "timestamp": asyncio.get_event_loop().time(),
                },
            },
        )

        # è°ƒç”¨TTSç”Ÿæˆè¯­éŸ³
        await process_tts_generation(client_id, ai_response)

    except Exception as e:
        logger.error(f"[LLMProcessor] LLMå¤„ç†å¤±è´¥: {e}")
        await manager.send_message(
            client_id,
            {
                "type": "error",
                "data": {
                    "code": "LLM_PROCESSING_ERROR",
                    "message": f"AIå›å¤ç”Ÿæˆå¤±è´¥: {str(e)}",
                    "retryable": True,
                },
            },
        )


async def process_tts_generation(
    client_id: str, text: str, is_immediate: bool = False, is_final: bool = False
):
    """å¤„ç†TTSè¯­éŸ³åˆæˆï¼ˆæ”¯æŒåŒè·¯å¾„æ ‡è®°ï¼‰"""
    try:
        # ç¡®å®šTTSç±»å‹æ ‡è®°
        tts_type = "å³æ—¶" if is_immediate else ("æœ€ç»ˆ" if is_final else "å¸¸è§„")
        logger.info(
            f"[TTSProcessor] ä¸ºå®¢æˆ·ç«¯ {client_id} ç”Ÿæˆ{tts_type}è¯­éŸ³: {text[:50]}..."
        )

        # å‘é€TTSå¼€å§‹ä¿¡å·
        message_type = (
            "tts_immediate_start"
            if is_immediate
            else ("tts_final_start" if is_final else "tts_start")
        )

        await manager.send_message(
            client_id,
            {
                "type": message_type,
                "data": {
                    "message": f"æ­£åœ¨ç”Ÿæˆ{tts_type}è¯­éŸ³...",
                    "is_immediate": is_immediate,
                    "is_final": is_final,
                },
            },
        )

        if volcengine_service:
            try:
                # è°ƒç”¨TTSæœåŠ¡
                audio_data = await volcengine_service.text_to_speech(text)

                if audio_data and len(audio_data) > 0:
                    # ç¼–ç éŸ³é¢‘æ•°æ®
                    audio_base64 = base64.b64encode(audio_data).decode("utf-8")

                    # å‘é€TTSç»“æœ
                    result_type = (
                        "tts_immediate_result"
                        if is_immediate
                        else ("tts_final_result" if is_final else "tts_result")
                    )

                    await manager.send_message(
                        client_id,
                        {
                            "type": result_type,
                            "data": {
                                "audioData": audio_base64,
                                "format": "mp3",
                                "isLast": True,
                                "is_immediate": is_immediate,
                                "is_final": is_final,
                                "text": text,  # åŒ…å«æºæ–‡æœ¬ç”¨äºå‰ç«¯æ˜¾ç¤º
                            },
                        },
                    )
                    logger.info(
                        f"[TTSProcessor] {tts_type}TTSæˆåŠŸï¼ŒéŸ³é¢‘å¤§å°: {len(audio_data)} bytes"
                    )
                else:
                    raise Exception("TTSæœåŠ¡è¿”å›ç©ºéŸ³é¢‘æ•°æ®")

            except Exception as tts_error:
                logger.error(f"[TTSProcessor] TTSè°ƒç”¨å¤±è´¥: {tts_error}")
                # å‘é€TTSä¸å¯ç”¨ä¿¡å·
                await manager.send_message(
                    client_id,
                    {
                        "type": "tts_unavailable",
                        "data": {"message": f"è¯­éŸ³åˆæˆæš‚ä¸å¯ç”¨: {str(tts_error)}"},
                    },
                )
        else:
            # é™çº§å¤„ç†ï¼šåªå‘é€æ–‡æœ¬
            await manager.send_message(
                client_id,
                {
                    "type": "tts_unavailable",
                    "data": {"message": "è¯­éŸ³åˆæˆæœåŠ¡æš‚ä¸å¯ç”¨"},
                },
            )

    except Exception as e:
        logger.error(f"[TTSProcessor] TTSå¤„ç†å¤±è´¥: {e}")
        await manager.send_message(
            client_id,
            {
                "type": "error",
                "data": {
                    "code": "TTS_PROCESSING_ERROR",
                    "message": f"è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}",
                    "retryable": True,
                },
            },
        )


async def process_interrupt(client_id: str):
    """å¤„ç†è¯­éŸ³æ‰“æ–­"""
    logger.info(f"[InterruptProcessor] å¤„ç†å®¢æˆ·ç«¯ {client_id} çš„æ‰“æ–­ä¿¡å·")

    # åœæ­¢å½“å‰å¤„ç†
    manager.update_conversation_state(client_id, {"is_processing": False})

    # å‘é€æ‰“æ–­ç¡®è®¤
    await manager.send_message(
        client_id,
        {
            "type": "interrupt_acknowledged",
            "data": {"message": "æ‰“æ–­å·²å¤„ç†ï¼Œå¯ä»¥ç»§ç»­è¯´è¯"},
        },
    )


async def start_conversation(client_id: str):
    """å¼€å§‹å¯¹è¯"""
    logger.info(f"[ConversationManager] å®¢æˆ·ç«¯ {client_id} å¼€å§‹å¯¹è¯")

    # é‡ç½®å¯¹è¯çŠ¶æ€
    manager.update_conversation_state(
        client_id, {"messages": [], "is_processing": False}
    )

    await manager.send_message(
        client_id,
        {"type": "conversation_started", "data": {"message": "å¯¹è¯å·²å¼€å§‹ï¼Œè¯·å¼€å§‹è¯´è¯"}},
    )


async def end_conversation(client_id: str):
    """ç»“æŸå¯¹è¯"""
    logger.info(f"[ConversationManager] å®¢æˆ·ç«¯ {client_id} ç»“æŸå¯¹è¯")

    # ä¿å­˜å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰
    conv_state = manager.get_conversation_state(client_id)
    messages = conv_state.get("messages", [])
    if messages:
        logger.info(f"[ConversationManager] å¯¹è¯åŒ…å« {len(messages)} æ¡æ¶ˆæ¯")

    # é‡ç½®çŠ¶æ€
    manager.update_conversation_state(
        client_id, {"messages": [], "is_processing": False}
    )

    await manager.send_message(
        client_id, {"type": "conversation_ended", "data": {"message": "å¯¹è¯å·²ç»“æŸ"}}
    )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        app, host=config.HOST, port=config.PORT, log_level=config.LOG_LEVEL.lower()
    )
