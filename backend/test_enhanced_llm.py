#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºLLMæœåŠ¡
æµ‹è¯•åŒè·¯å¾„å“åº”æœºåˆ¶ã€OpenAI SDKé›†æˆå’Œå„ä¸ªç®¡ç†å™¨ç»„ä»¶
"""

import sys
import os
import json
import logging
import asyncio
from datetime import datetime

# Add the backend directory to Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def test_enhanced_llm_service():
    """æµ‹è¯•å¢å¼ºLLMæœåŠ¡çš„å„é¡¹åŠŸèƒ½"""

    print("=" * 70)
    print("æµ‹è¯•å¢å¼ºLLMæœåŠ¡ - åŒè·¯å¾„å“åº”æœºåˆ¶")
    print("=" * 70)

    try:
        from config import Config
        from services.volcengine_llm_enhanced import (
            VolcengineEnhancedLLMService,
            DualPathResponse,
        )
        from services.tools.tool_registry import global_tool_registry

        # è¯»å–é…ç½®
        config = Config()

        # åˆå§‹åŒ–å·¥å…·æ³¨å†Œå™¨
        print("\n1. åˆå§‹åŒ–å·¥å…·æ³¨å†Œå™¨...")
        global_tool_registry.initialize_default_tools(
            n8n_webhook_url="https://kai.kjwlabs.com/webhook-test/n8n"
        )
        print(f"   âœ… å·¥å…·æ³¨å†Œå®Œæˆï¼Œå…±æ³¨å†Œ {len(global_tool_registry)} ä¸ªå·¥å…·")
        print(f"   ğŸ“‹ å¯ç”¨å·¥å…·: {global_tool_registry.list_tools()}")

        # åˆå§‹åŒ–å¢å¼ºLLMæœåŠ¡
        print("\n2. åˆå§‹åŒ–å¢å¼ºLLMæœåŠ¡...")
        enhanced_llm = VolcengineEnhancedLLMService(
            api_key=config.VOLCENGINE_API_KEY,
            endpoint_id=config.VOLCENGINE_ENDPOINT_ID,
            tool_registry=global_tool_registry,
            enable_function_calling=True,
        )
        print("   âœ… å¢å¼ºLLMæœåŠ¡åˆå§‹åŒ–å®Œæˆ")

        # æµ‹è¯•è¿æ¥
        print("\n3. æµ‹è¯•æœåŠ¡è¿æ¥...")
        connection_result = await enhanced_llm.test_connection()
        print(f"   è¿æ¥çŠ¶æ€: {connection_result['status']}")
        if connection_result["status"] == "âœ… æ­£å¸¸":
            print(f"   æ¨¡å‹: {connection_result['model']}")
            print(f"   å“åº”é¢„è§ˆ: {connection_result['response_preview']}")

        # æµ‹è¯•ç®€å•å¯¹è¯ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰
        print("\n4. æµ‹è¯•ç®€å•å¯¹è¯...")
        simple_messages = [{"role": "user", "content": "ä½ å¥½Amyï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]

        print("   ç”¨æˆ·: ä½ å¥½Amyï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        simple_result = await enhanced_llm.generate_dual_path_response(simple_messages)
        print(f"   Amyå›å¤: {simple_result.immediate_response}")
        print(f"   æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨: {simple_result.has_tool_calls}")

        # æµ‹è¯•åŒè·¯å¾„å“åº”ï¼ˆå¸¦å·¥å…·è°ƒç”¨ï¼‰
        print("\n5. æµ‹è¯•åŒè·¯å¾„å“åº”ï¼ˆå·¥å…·è°ƒç”¨ï¼‰...")

        # åˆ›å»ºTTSæ¨¡æ‹Ÿå›è°ƒ
        tts_outputs = []
        patience_outputs = []

        async def immediate_callback(text: str):
            """æ¨¡æ‹Ÿå³æ—¶TTSå›è°ƒ"""
            tts_outputs.append(f"[å³æ—¶TTS] {text}")
            print(f"   ğŸ”Š å³æ—¶æ’­æ”¾: {text}")

        async def patience_callback(text: str):
            """æ¨¡æ‹Ÿè€å¿ƒç­‰å¾…å›è°ƒ"""
            patience_outputs.append(f"[è€å¿ƒTTS] {text}")
            print(f"   â° è€å¿ƒæç¤º: {text}")

        # å‘é€éœ€è¦å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯
        tool_messages = [
            {"role": "user", "content": "å¸®æˆ‘å‘é€ä¸€å°é‚®ä»¶ç»™æœ±å˜‰é›¯ï¼Œå†…å®¹æ˜¯æµ‹è¯•é‚®ä»¶"}
        ]

        print("   ç”¨æˆ·: å¸®æˆ‘å‘é€ä¸€å°é‚®ä»¶ç»™æœ±å˜‰é›¯ï¼Œå†…å®¹æ˜¯æµ‹è¯•é‚®ä»¶")
        print("   å¼€å§‹åŒè·¯å¾„å¤„ç†...")

        dual_result = await enhanced_llm.generate_dual_path_response(
            tool_messages,
            immediate_callback=immediate_callback,
            patience_callback=patience_callback,
        )

        print(f"\n   âœ… åŒè·¯å¾„å“åº”å®Œæˆ:")
        print(f"   ğŸ“¤ å³æ—¶å›å¤: {dual_result.immediate_response}")
        print(f"   ğŸ”§ æœ‰å·¥å…·è°ƒç”¨: {dual_result.has_tool_calls}")

        if dual_result.has_tool_calls and dual_result.tool_response:
            print(f"   ğŸ“¨ æœ€ç»ˆå›å¤: {dual_result.tool_response}")
            print(f"   â±ï¸  æ‰§è¡Œæ—¶é—´: {dual_result.tool_execution_time:.2f}s")

        # æµ‹è¯•å…¼å®¹æ€§æ¥å£
        print("\n6. æµ‹è¯•å…¼å®¹æ€§æ¥å£...")
        compat_messages = [{"role": "user", "content": "ç®€å•é—®å€™ä¸€ä¸‹"}]

        compat_response = await enhanced_llm.generate_chat_response(compat_messages)
        print(f"   å…¼å®¹æ¥å£å›å¤: {compat_response}")

        # æµ‹è¯•å„ä¸ªç®¡ç†å™¨ç»„ä»¶
        print("\n7. æµ‹è¯•å„ä¸ªç®¡ç†å™¨ç»„ä»¶...")

        # æµ‹è¯•å³æ—¶å“åº”ç®¡ç†å™¨
        immediate_manager = enhanced_llm.immediate_manager
        immediate_resp = await immediate_manager.generate_immediate_response(
            "æŸ¥è¯¢æ—¥ç¨‹", []
        )
        print(f"   å³æ—¶å“åº”ç®¡ç†å™¨: {immediate_resp}")

        # æµ‹è¯•è€å¿ƒç®¡ç†å™¨
        patience_manager = enhanced_llm.tool_manager.patience_manager
        test_callback_called = []

        async def test_patience_callback(msg):
            test_callback_called.append(msg)

        # æ¨¡æ‹Ÿ5ç§’ç­‰å¾…
        await patience_manager.handle_long_wait(6.0, test_patience_callback)
        if test_callback_called:
            print(f"   è€å¿ƒç®¡ç†å™¨: {test_callback_called[0]}")

        # æ˜¾ç¤ºæ‰€æœ‰è¾“å‡º
        print("\n8. å¤„ç†è¿‡ç¨‹è®°å½•:")
        if tts_outputs:
            print("   TTSè¾“å‡ºè®°å½•:")
            for output in tts_outputs:
                print(f"     {output}")

        if patience_outputs:
            print("   è€å¿ƒæç¤ºè®°å½•:")
            for output in patience_outputs:
                print(f"     {output}")

        print("\n" + "=" * 70)
        print("å¢å¼ºLLMæœåŠ¡æµ‹è¯•å®Œæˆï¼")
        print("=" * 70)

        print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
        print("1. âœ… å·¥å…·æ³¨å†Œå™¨åˆå§‹åŒ–æ­£å¸¸")
        print("2. âœ… å¢å¼ºLLMæœåŠ¡åˆå§‹åŒ–æ­£å¸¸")
        print("3. âœ… æœåŠ¡è¿æ¥æµ‹è¯•æ­£å¸¸")
        print("4. âœ… ç®€å•å¯¹è¯åŠŸèƒ½æ­£å¸¸")
        print("5. âœ… åŒè·¯å¾„å“åº”æœºåˆ¶æ­£å¸¸")
        print("6. âœ… å…¼å®¹æ€§æ¥å£æ­£å¸¸")
        print("7. âœ… å„ç®¡ç†å™¨ç»„ä»¶æ­£å¸¸")

    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„ä¾èµ–ï¼špip install openai")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"æµ‹è¯•å¼‚å¸¸: {str(e)}", exc_info=True)
        sys.exit(1)


async def test_performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼šåŸç‰ˆ vs å¢å¼ºç‰ˆ"""

    print("\n" + "=" * 70)
    print("æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼šåŸç‰ˆLLM vs å¢å¼ºç‰ˆLLM")
    print("=" * 70)

    try:
        from config import Config
        from services.volcengine_llm import VolcengineLLMService
        from services.volcengine_llm_enhanced import VolcengineEnhancedLLMService
        from services.tools.tool_registry import global_tool_registry
        import time

        config = Config()

        # ç¡®ä¿å·¥å…·å·²æ³¨å†Œ
        if len(global_tool_registry) == 0:
            global_tool_registry.initialize_default_tools(
                n8n_webhook_url="https://kai.kjwlabs.com/webhook-test/n8n"
            )

        # åˆ›å»ºä¸¤ä¸ªæœåŠ¡å®ä¾‹
        original_llm = VolcengineLLMService(
            api_key=config.VOLCENGINE_API_KEY,
            endpoint_id=config.VOLCENGINE_ENDPOINT_ID,
            tool_registry=global_tool_registry,
            enable_function_calling=True,
        )

        enhanced_llm = VolcengineEnhancedLLMService(
            api_key=config.VOLCENGINE_API_KEY,
            endpoint_id=config.VOLCENGINE_ENDPOINT_ID,
            tool_registry=global_tool_registry,
            enable_function_calling=True,
        )

        # æµ‹è¯•æ¶ˆæ¯
        test_messages = [{"role": "user", "content": "å‘é€æµ‹è¯•é‚®ä»¶ç»™admin@example.com"}]

        print("\næµ‹è¯•æ¶ˆæ¯: å‘é€æµ‹è¯•é‚®ä»¶ç»™admin@example.com")

        # æµ‹è¯•åŸç‰ˆLLM
        print("\n1. åŸç‰ˆLLMæœåŠ¡æµ‹è¯•...")
        start_time = time.time()

        original_response = await original_llm.generate_chat_response(test_messages)

        original_time = time.time() - start_time
        print(f"   â±ï¸  åŸç‰ˆæ€»è€—æ—¶: {original_time:.2f}s")
        print(f"   ğŸ“ åŸç‰ˆå›å¤: {original_response[:100]}...")

        # æµ‹è¯•å¢å¼ºç‰ˆLLM
        print("\n2. å¢å¼ºç‰ˆLLMæœåŠ¡æµ‹è¯•...")

        immediate_received = []
        start_time = time.time()

        async def immediate_callback(text: str):
            if not immediate_received:  # åªè®°å½•ç¬¬ä¸€æ¬¡å³æ—¶å›å¤æ—¶é—´
                immediate_time = time.time() - start_time
                immediate_received.append(immediate_time)
                print(f"   âš¡ å³æ—¶å›å¤è€—æ—¶: {immediate_time:.2f}s")
                print(f"   ğŸ“¤ å³æ—¶å›å¤: {text}")

        enhanced_result = await enhanced_llm.generate_dual_path_response(
            test_messages, immediate_callback=immediate_callback
        )

        total_time = time.time() - start_time
        print(f"   â±ï¸  å¢å¼ºç‰ˆæ€»è€—æ—¶: {total_time:.2f}s")

        if enhanced_result.has_tool_calls:
            print(f"   ğŸ“¨ æœ€ç»ˆå›å¤: {enhanced_result.tool_response[:100]}...")
        else:
            print(f"   ğŸ“ ç›´æ¥å›å¤: {enhanced_result.immediate_response[:100]}...")

        # æ€§èƒ½åˆ†æ
        print("\nğŸ“Š æ€§èƒ½åˆ†æ:")
        if immediate_received:
            immediate_time = immediate_received[0]
            print(f"   å³æ—¶å“åº”é€Ÿåº¦: {immediate_time:.2f}s (ç”¨æˆ·ä½“éªŒæå‡)")
            print(
                f"   æ€»å“åº”æ—¶é—´å¯¹æ¯”: åŸç‰ˆ {original_time:.2f}s vs å¢å¼ºç‰ˆ {total_time:.2f}s"
            )

            if immediate_time < 2.0:
                print("   âœ… å³æ—¶å“åº”è¾¾æ ‡ (< 2ç§’)")
            else:
                print("   âš ï¸  å³æ—¶å“åº”éœ€è¦ä¼˜åŒ–")

            improvement = ((original_time - immediate_time) / original_time) * 100
            print(f"   ğŸš€ ç”¨æˆ·ä½“éªŒæå‡: {improvement:.1f}% (åŸºäºå³æ—¶å“åº”)")

    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {str(e)}", exc_info=True)


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¿è¡Œä¸»è¦æµ‹è¯•
        asyncio.run(test_enhanced_llm_service())

        # è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•
        asyncio.run(test_performance_comparison())

    except KeyboardInterrupt:
        print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
